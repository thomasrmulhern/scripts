{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import statsmodels as sm\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer, Binarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scripts for preprocessing data for machine learning\n",
    "#Borrowed generously from https://machinelearningmastery.com/prepare-data-machine-learning-python-scikit-learn/\n",
    "\n",
    "\n",
    "class Prepare:  \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    Functions: prepare_data_from_csv, describe_data, rescale_data, standardize_data, normalize_data, binarize_data\n",
    "    Input: file_path_as_string, y_column_name, column_names=None, header=0\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, file_path_as_string, y_column_name, column_names, header):\n",
    "        self.file_path_as_string = file_path_as_string \n",
    "        self.y_column_name  = y_column_name\n",
    "        self.column_names = column_names\n",
    "        self.header = 0\n",
    "\n",
    "\n",
    "\n",
    "    def prepare_data_from_csv(self):\n",
    "\n",
    "        '''Import and prepare data'''\n",
    "\n",
    "        dataframe = pd.read_csv(self.file_path_as_string, names=self.column_names, delimiter=',',header=self.header)\n",
    "        self.prepared_df = dataframe\n",
    "        if self.header != None:\n",
    "            dataframe.columns = [x.replace(' ', '_') for x in dataframe.columns]\n",
    "        print(dataframe.head())\n",
    "\n",
    "        self.X = dataframe.drop(self.y_column_name, axis=1)\n",
    "        self.y = dataframe[self.y_column_name]\n",
    "\n",
    "        prepared_df = dataframe\n",
    "        return self.prepared_df, self.X, self.y\n",
    "\n",
    "\n",
    "    def describe_data(self, prepared_df):\n",
    "\n",
    "        ''' Print shape and descriptive statistics'''\n",
    "\n",
    "        print('Info: ','\\n'+'--'*25 + f'\\n{prepared_df.info()}')\n",
    "        print('--'*25)\n",
    "        print('Nulls: ', '\\n'+'--'*25 + f'\\n{prepared_df.isnull().sum()}')\n",
    "        print('--'*25, '\\n'+'--'*25)\n",
    "        print('Describe: ', '\\n'+'--'*25 + f'\\n{prepared_df.describe()}')\n",
    "        print('--'*25, '\\n'+'--'*25)\n",
    "\n",
    "        \n",
    "    def rescale_data(self, X): \n",
    "\n",
    "        '''When your data is comprised of attributes with varying scales, many machine learning algorithms can benefit \n",
    "        from rescaling the attributes to all have the same scale.Often this is referred to as normalization and attributes\n",
    "        are often rescaled into the range between 0 and 1. This is useful for optimization algorithms in used in the core\n",
    "        of machine learning algorithms like gradient descent. It is also useful for algorithms that weight inputs like \n",
    "        regression and neural networks and algorithms that use distance measures like K-Nearest Neighbors.\n",
    "\n",
    "        Input: dataframe data to be used for features\n",
    "        Return: scaled data\n",
    "    '''\n",
    "\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        rescaledX = scaler.fit_transform(self.X)\n",
    "\n",
    "        # summarize transformed data\n",
    "        np.set_printoptions(precision=3)\n",
    "        print(rescaledX[0:5,:])\n",
    "\n",
    "        return rescaledX\n",
    "\n",
    "\n",
    "    def standardize_data(self, X):\n",
    "\n",
    "        '''Standardize attributes with a Gaussian distribution and differing \n",
    "        means and standard deviations to a standard Gaussian distribution with a mean of 0 and a standard deviation of \n",
    "        1.It is most suitable for techniques that assume a Gaussian distribution in the input variables and work better \n",
    "        with rescaled data, such as linear regression, logistic regression and linear discriminate analysis.\n",
    "\n",
    "        Input: dataframe data to be used for features\n",
    "        Return: standardized data\n",
    "        '''\n",
    "\n",
    "        stand_scaler = StandardScaler().fit(X)\n",
    "        stand_rescaledX = stand_scaler.transform(self.X)\n",
    "\n",
    "        # summarize transformed data\n",
    "        np.set_printoptions(precision=3)\n",
    "        print(stand_rescaledX[0:5,:])\n",
    "\n",
    "        return stand_rescaledX\n",
    "\n",
    "\n",
    "    def normalize_data(self, X):\n",
    "\n",
    "        '''Rescale each observation (row) to have a length of 1 (called a unit norm in linear algebra). This \n",
    "        preprocessing can be useful for sparse datasets (lots of zeros) with attributes of varying scales when \n",
    "        using algorithms that weight input values such as neural networks and algorithms that use distance measures \n",
    "        such as K-Nearest Neighbors.\n",
    "\n",
    "        Input: dataframe data to be used for features\n",
    "        Return: normalized data'''\n",
    "\n",
    "        norm_scaler = Normalizer().fit(self.X)\n",
    "        normalizedX = norm_scaler.transform(self.X)\n",
    "\n",
    "        # summarize transformed data\n",
    "        np.set_printoptions(precision=3)\n",
    "        print(normalizedX[0:5,:])\n",
    "\n",
    "        return normalizedX\n",
    "    \n",
    "\n",
    "    def binarize_data(self, X):\n",
    "\n",
    "        '''Transform your data using a binary threshold. All values above the threshold are marked 1 and all\n",
    "        equal to or below are marked as 0. This is called binarizing your data or threshold your data. It can be useful\n",
    "        when you have probabilities that you want to make crisp values. It is also useful when feature engineering and \n",
    "        you want to add new features that indicate something meaningful.\n",
    "\n",
    "        Input: dataframe data to be used for features\n",
    "        Return: binarized data\n",
    "        '''\n",
    "\n",
    "        binarizer = Binarizer(threshold=0.0).fit(self.X)\n",
    "        binaryX = binarizer.transform(X)\n",
    "\n",
    "        # summarize transformed data\n",
    "        np.set_printoptions(precision=3)\n",
    "        print(binaryX[0:5,:])\n",
    "\n",
    "        return binaryX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   preg  plas  pres  skin  test  mass   pedi  age  class\n",
      "0     1    85    66    29     0  26.6  0.351   31      0\n",
      "1     8   183    64     0     0  23.3  0.672   32      1\n",
      "2     1    89    66    23    94  28.1  0.167   21      0\n",
      "3     0   137    40    35   168  43.1  2.288   33      1\n",
      "4     5   116    74     0     0  25.6  0.201   30      0\n"
     ]
    }
   ],
   "source": [
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "prep_obj = Prepare('pima-indians-diabetes.data copy.csv', 'class', names, 0) \n",
    "prepared_df, X, y = prep_obj.prepare_data_from_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 767 entries, 0 to 766\n",
      "Data columns (total 9 columns):\n",
      "preg     767 non-null int64\n",
      "plas     767 non-null int64\n",
      "pres     767 non-null int64\n",
      "skin     767 non-null int64\n",
      "test     767 non-null int64\n",
      "mass     767 non-null float64\n",
      "pedi     767 non-null float64\n",
      "age      767 non-null int64\n",
      "class    767 non-null int64\n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.0 KB\n",
      "Info:  \n",
      "--------------------------------------------------\n",
      "None\n",
      "--------------------------------------------------\n",
      "Nulls:  \n",
      "--------------------------------------------------\n",
      "preg     0\n",
      "plas     0\n",
      "pres     0\n",
      "skin     0\n",
      "test     0\n",
      "mass     0\n",
      "pedi     0\n",
      "age      0\n",
      "class    0\n",
      "dtype: int64\n",
      "-------------------------------------------------- \n",
      "--------------------------------------------------\n",
      "Describe:  \n",
      "--------------------------------------------------\n",
      "             preg        plas        pres        skin        test        mass  \\\n",
      "count  767.000000  767.000000  767.000000  767.000000  767.000000  767.000000   \n",
      "mean     3.842243  120.859192   69.101695   20.517601   79.903520   31.990482   \n",
      "std      3.370877   31.978468   19.368155   15.954059  115.283105    7.889091   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      1.000000   99.000000   62.000000    0.000000    0.000000   27.300000   \n",
      "50%      3.000000  117.000000   72.000000   23.000000   32.000000   32.000000   \n",
      "75%      6.000000  140.000000   80.000000   32.000000  127.500000   36.600000   \n",
      "max     17.000000  199.000000  122.000000   99.000000  846.000000   67.100000   \n",
      "\n",
      "             pedi         age       class  \n",
      "count  767.000000  767.000000  767.000000  \n",
      "mean     0.471674   33.219035    0.348110  \n",
      "std      0.331497   11.752296    0.476682  \n",
      "min      0.078000   21.000000    0.000000  \n",
      "25%      0.243500   24.000000    0.000000  \n",
      "50%      0.371000   29.000000    0.000000  \n",
      "75%      0.625000   41.000000    1.000000  \n",
      "max      2.420000   81.000000    1.000000  \n",
      "-------------------------------------------------- \n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "prep_obj.describe_data(prepared_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.059 0.427 0.541 0.293 0.    0.396 0.117 0.167]\n",
      " [0.471 0.92  0.525 0.    0.    0.347 0.254 0.183]\n",
      " [0.059 0.447 0.541 0.232 0.111 0.419 0.038 0.   ]\n",
      " [0.    0.688 0.328 0.354 0.199 0.642 0.944 0.2  ]\n",
      " [0.294 0.583 0.607 0.    0.    0.382 0.053 0.15 ]]\n"
     ]
    }
   ],
   "source": [
    "resc_x = prep_obj.rescale_data(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.844 -1.122 -0.16   0.532 -0.694 -0.684 -0.364 -0.189]\n",
      " [ 1.234  1.944 -0.264 -1.287 -0.694 -1.102  0.605 -0.104]\n",
      " [-0.844 -0.997 -0.16   0.156  0.122 -0.493 -0.92  -1.04 ]\n",
      " [-1.141  0.505 -1.504  0.908  0.765  1.409  5.483 -0.019]\n",
      " [ 0.344 -0.152  0.253 -1.287 -0.694 -0.811 -0.817 -0.274]]\n"
     ]
    }
   ],
   "source": [
    "stand_x = prep_obj.standardize_data(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.008 0.716 0.556 0.244 0.    0.224 0.003 0.261]\n",
      " [0.04  0.924 0.323 0.    0.    0.118 0.003 0.162]\n",
      " [0.007 0.588 0.436 0.152 0.622 0.186 0.001 0.139]\n",
      " [0.    0.596 0.174 0.152 0.731 0.188 0.01  0.144]\n",
      " [0.035 0.81  0.517 0.    0.    0.179 0.001 0.209]]\n"
     ]
    }
   ],
   "source": [
    "norm_x = prep_obj.normalize_data(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 0. 1. 1. 1.]\n",
      " [1. 1. 1. 0. 0. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 0. 0. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "bin_x = prep_obj.binarize_data(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
