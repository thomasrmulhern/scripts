{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import statsmodels as sm\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer, Binarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scripts for preprocessing data for machine learning\n",
    "#Borrowed generously from https://machinelearningmastery.com/prepare-data-machine-learning-python-scikit-learn/\n",
    "\n",
    "\n",
    "class Prepare:  \n",
    "    '''\n",
    "    Prepare data for machine learning in Python using scikit-learn.\n",
    "    \n",
    "    Functions: prepare_data_from_csv, describe_data, rescale_data, standardize_data, normalize_data, binarize_data\n",
    "    Input: file_path_as_string, y_column_name, column_names=None, header=0\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, file_path_as_string, y_column_name, column_names, header):\n",
    "        self.file_path_as_string = file_path_as_string \n",
    "        self.y_column_name  = y_column_name\n",
    "        self.column_names = column_names\n",
    "        self.header = 0\n",
    "\n",
    "\n",
    "\n",
    "    def prepare_data_from_csv(self):\n",
    "\n",
    "        '''Import and prepare data'''\n",
    "\n",
    "        dataframe = pd.read_csv(self.file_path_as_string, names=self.column_names, delimiter=',',header=self.header)\n",
    "        \n",
    "        if self.header != None:\n",
    "            dataframe.columns = [x.replace(' ', '_') for x in dataframe.columns]\n",
    "        print(dataframe.head())\n",
    "\n",
    "        self.X = dataframe.drop(self.y_column_name, axis=1)\n",
    "        self.y = dataframe[self.y_column_name]\n",
    "\n",
    "        prepared_df = dataframe\n",
    "        #self.prepared_df = dataframe\n",
    "        \n",
    "        return prepared_df, self.X, self.y #self.prepared_df\n",
    "\n",
    "\n",
    "    def describe_data(self, prepared_df):\n",
    "\n",
    "        ''' Print shape and descriptive statistics'''\n",
    "        \n",
    "        print('\\nColumns: ','\\n'+'--'*25 + f'\\n{prepared_df.columns}')\n",
    "        print('--'*25, '\\n'+'--'*25)\n",
    "        print('\\nInfo: ','\\n'+'--'*25 + f'\\n{prepared_df.info()}')\n",
    "        print('--'*25, '\\n'+'--'*25)\n",
    "        print('\\nUnique: ','\\n'+'--'*25 + f'\\n{prepared_df.nunique()}')\n",
    "        print('--'*25, '\\n'+'--'*25)\n",
    "        print('\\nNulls: ', '\\n'+'--'*25 + f'\\n{prepared_df.isnull().sum()}')\n",
    "        print('--'*25, '\\n'+'--'*25)\n",
    "        print('\\nDescribe: ', '\\n'+'--'*25 + f'\\n{prepared_df.describe()}')\n",
    "        print('--'*25, '\\n'+'--'*25)\n",
    "        print('\\nHead: ', '\\n'+'--'*25 + f'\\n{prepared_df.head()}')\n",
    "        print('--'*25, '\\n'+'--'*25)\n",
    "\n",
    "        \n",
    "    def rescale_data(self, X): \n",
    "\n",
    "        '''\n",
    "        When your data is comprised of attributes with varying scales, many machine learning algorithms \n",
    "        can benefit from rescaling the attributes to all have the same scale.Often this is referred to as \n",
    "        normalization and attributes are often rescaled into the range between 0 and 1. This is useful for \n",
    "        optimization algorithms in used in the core of machine learning algorithms like gradient descent. \n",
    "        It is also useful for algorithms that weight inputs like regression and neural networks and algorithms \n",
    "        that use distance measures like K-Nearest Neighbors.\n",
    "\n",
    "        Input: dataframe data to be used for features\n",
    "        Return: scaled data\n",
    "        '''\n",
    "\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        rescaledX = scaler.fit_transform(self.X)\n",
    "\n",
    "        # summarize transformed data\n",
    "        np.set_printoptions(precision=3)\n",
    "        print(rescaledX[0:5,:])\n",
    "\n",
    "        return rescaledX\n",
    "\n",
    "\n",
    "    def standardize_data(self, X):\n",
    "\n",
    "        '''\n",
    "        Standardize attributes with a Gaussian distribution and differing means and standard deviations\n",
    "        to a standard Gaussian distribution with a mean of 0 and a standard deviation of 1. It is most suitable\n",
    "        for techniques that assume a Gaussian distribution in the input variables and work better with rescaled \n",
    "        data, such as linear regression, logistic regression and linear discriminate analysis.\n",
    "\n",
    "        Input: dataframe data to be used for features\n",
    "        Return: standardized data\n",
    "        '''\n",
    "\n",
    "        stand_scaler = StandardScaler().fit(X)\n",
    "        stand_rescaledX = stand_scaler.transform(self.X)\n",
    "\n",
    "        # summarize transformed data\n",
    "        np.set_printoptions(precision=3)\n",
    "        print(stand_rescaledX[0:5,:])\n",
    "\n",
    "        return stand_rescaledX\n",
    "\n",
    "\n",
    "    def normalize_data(self, X):\n",
    "\n",
    "        '''\n",
    "        Rescale each observation (row) to have a length of 1 (called a unit norm in linear algebra). This \n",
    "        preprocessing can be useful for sparse datasets (lots of zeros) with attributes of varying scales when \n",
    "        using algorithms that weight input values such as neural networks and algorithms that use distance measures \n",
    "        such as K-Nearest Neighbors.\n",
    "\n",
    "        Input: dataframe data to be used for features\n",
    "        Return: normalized data\n",
    "        '''\n",
    "\n",
    "        norm_scaler = Normalizer().fit(self.X)\n",
    "        normalizedX = norm_scaler.transform(self.X)\n",
    "\n",
    "        # summarize transformed data\n",
    "        np.set_printoptions(precision=3)\n",
    "        print(normalizedX[0:5,:])\n",
    "\n",
    "        return normalizedX\n",
    "    \n",
    "\n",
    "    def binarize_data(self, X):\n",
    "\n",
    "        '''\n",
    "        Transform data using a binary threshold. All values above the threshold are marked 1 and all\n",
    "        equal to or below are marked as 0. This is called binarizing your data or threshold your data. It can\n",
    "        be useful when you have probabilities that you want to make crisp values. It is also useful when feature\n",
    "        engineering and you want to add new features that indicate something meaningful.\n",
    "\n",
    "        Input: dataframe data to be used for features\n",
    "        Return: binarized data\n",
    "        '''\n",
    "\n",
    "        binarizer = Binarizer(threshold=0.0).fit(self.X)\n",
    "        binaryX = binarizer.transform(X)\n",
    "\n",
    "        # summarize transformed data\n",
    "        np.set_printoptions(precision=3)\n",
    "        print(binaryX[0:5,:])\n",
    "\n",
    "        return binaryX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "# prep_obj = Prepare('data/pima-indians-diabetes.data copy.csv', 'class', names, 0) \n",
    "# prepared_df, X, y = prep_obj.prepare_data_from_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prep_obj.describe_data(prepared_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resc_x = prep_obj.rescale_data(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stand_x = prep_obj.standardize_data(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#norm_x = prep_obj.normalize_data(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bin_x = prep_obj.binarize_data(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
